[base]
env_name = azuki_local

[vec]
backend = Multiprocessing
num_envs = 1024
num_workers = 8 
batch_size = 512
zero_copy = True

[env]

[policy]
subaction_temperature_initial = 1.2
subaction_temperature_final = 1.2
subaction_temperature_anneal_start_frac = 0.6
subaction_temperature_anneal_end_frac = 0.9
; Optional absolute-step overrides (take precedence over *_frac):
; subaction_temperature_anneal_start_step = 150000000
; subaction_temperature_anneal_end_step = 225000000
smoothing_eps_initial = 0.05
smoothing_eps_final = 0.05
smoothing_eps_anneal_start_frac = 0.6
smoothing_eps_anneal_end_frac = 0.9
; smoothing_eps_anneal_start_step = 150000000
; smoothing_eps_anneal_end_step = 225000000

[league]
enable = False
state_path = experiments/league_state.json
latest_ratio = 0.85
randomize_learner_seat = True
activate_after_steps = 0
checkpoint_add_interval = 1
eval_interval = 1
eval_mode = inline
quick_eval_interval = 3
quick_eval_episodes = 8
full_eval_interval = 12
full_eval_episodes = 48
eval_episodes = 8
eval_max_steps = 400
keep_recent = 6
keep_mid = 4
keep_old = 3
min_candidate_epoch_gap = 1
promotion_min_winrate_vs_champion = 0.55
promotion_baseline_count = 2
promotion_min_winrate_vs_baseline = 0.50
promotion_min_games_vs_champion = 16
promotion_min_games_vs_baseline = 8
promotion_wilson_confidence_z = 1.28
opponent_dir = 
opponent_checkpoints = 

[train]
device = cuda
total_timesteps = 100000
batch_size = auto
min_batch_size = 32768
bptt_horizon = 16 
update_epochs = 2
vf_coef = 1.0
ent_coef = 0.01
ent_coef_anneal_initial = 0.01
ent_coef_anneal_final = 0.01
ent_coef_anneal_start_frac = 0.6
ent_coef_anneal_end_frac = 0.9
; Optional absolute-step overrides:
; ent_coef_anneal_start_step = 150000000
; ent_coef_anneal_end_step = 225000000
checkpoint_interval = 25000
max_checkpoints = 24
gamma = 0.99
gae_lambda = 0.95
learning_rate = 0.015
adam_beta1 = 0.9
compile = False 
